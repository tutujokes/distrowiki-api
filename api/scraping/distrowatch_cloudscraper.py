"""
Scraper do DistroWatch usando CloudScraper
Bypass automÃ¡tico de Cloudflare e proteÃ§Ãµes anti-bot.
"""

import logging
import cloudscraper
from typing import List, Dict, Optional
from datetime import datetime
from bs4 import BeautifulSoup

logger = logging.getLogger(__name__)


class DistroWatchCloudScraper:
    """
    Scraper para DistroWatch usando CloudScraper.
    
    CaracterÃ­sticas:
    - Bypass automÃ¡tico de Cloudflare
    - Leve e rÃ¡pido (sem navegador)
    - User-agent rotativo
    - Retry automÃ¡tico
    """
    
    def __init__(self, delay: int = 2):
        """
        Inicializa o scraper.
        
        Args:
            delay: Delay entre requests em segundos
        """
        self.base_url = "https://distrowatch.com"
        self.delay = delay
        self.scraper = cloudscraper.create_scraper(
            browser={
                'browser': 'chrome',
                'platform': 'windows',
                'desktop': True
            }
        )
        
    def scrape_distro_list(self) -> List[Dict]:
        """
        Scrape lista de distribuiÃ§Ãµes da pÃ¡gina de popularidade.
        
        Returns:
            Lista de dicionÃ¡rios com dados bÃ¡sicos das distros
        """
        logger.info("ğŸ” Iniciando scraping da lista de distribuiÃ§Ãµes...")
        
        url = f"{self.base_url}/popularity"
        
        try:
            logger.info(f"ğŸ“¡ Acessando: {url}")
            response = self.scraper.get(url, timeout=30)
            response.raise_for_status()
            
            logger.info(f"âœ… Status: {response.status_code}")
            
            # Parse HTML
            soup = BeautifulSoup(response.text, 'html.parser')
            distros = []
            
            # Na pÃ¡gina /popularity, os rankings estÃ£o em uma tabela simples
            # Busca todos os links de distros na pÃ¡gina
            links = soup.find_all('a', href=lambda x: x and 'table.php?distribution=' in x)
            
            if not links:
                logger.warning("âš ï¸ Nenhum link de distro encontrado na pÃ¡gina")
                return []
            
            logger.info(f"ğŸ“Š Encontrados {len(links)} links de distros")
            
            # Extrai dados de cada link
            seen_distros = set()  # Para evitar duplicatas
            
            for link in links:
                distro_name = link.get_text(strip=True)
                distro_url = link.get('href')
                
                # Evita duplicatas
                if distro_name in seen_distros:
                    continue
                seen_distros.add(distro_name)
                
                # Normaliza URL
                if not distro_url.startswith('http'):
                    distro_url = f"{self.base_url}/{distro_url}"
                
                # Tenta extrair o rank do contexto (linha da tabela)
                rank = None
                parent_tr = link.find_parent('tr')
                if parent_tr:
                    # Primeira cÃ©lula geralmente contÃ©m o rank
                    first_td = parent_tr.find('td')
                    if first_td:
                        rank_text = first_td.get_text(strip=True)
                        if rank_text.isdigit():
                            rank = rank_text
                
                # Se nÃ£o encontrou rank, usa posiÃ§Ã£o na lista
                if not rank:
                    rank = str(len(distros) + 1)
                
                distros.append({
                    'rank': rank,
                    'name': distro_name,
                    'url': distro_url
                })
            
            logger.info(f"âœ… Scraped {len(distros)} distribuiÃ§Ãµes Ãºnicas")
            return distros
            
        except Exception as e:
            logger.error(f"âŒ Erro ao fazer scraping da lista: {e}")
            logger.info("ğŸ’¡ Dica: Se estiver rodando localmente e DistroWatch estiver bloqueado, use GitHub Actions")
            return []
    
    def scrape_distro_details(self, distro_url: str) -> Optional[Dict]:
        """
        Scrape detalhes de uma distribuiÃ§Ã£o especÃ­fica.
        
        Args:
            distro_url: URL da pÃ¡gina da distro
        
        Returns:
            Dict com detalhes da distro ou None se falhar
        """
        logger.info(f"ğŸ“„ Scraping detalhes de: {distro_url}")
        
        try:
            response = self.scraper.get(distro_url, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            details = {}
            
            # Extrai informaÃ§Ãµes da pÃ¡gina
            # Based: seÃ§Ã£o com informaÃ§Ãµes bÃ¡sicas
            info_table = soup.find('table', class_='Info')
            
            if info_table:
                rows = info_table.find_all('tr')
                for row in rows:
                    cols = row.find_all('td')
                    if len(cols) >= 2:
                        key = cols[0].get_text(strip=True).lower().replace(':', '')
                        value = cols[1].get_text(strip=True)
                        details[key] = value
            
            return details
            
        except Exception as e:
            logger.error(f"âŒ Erro ao scraping detalhes: {e}")
            return None
    
    def scrape_all(self, limit: Optional[int] = None) -> List[Dict]:
        """
        Scrape completo: lista + detalhes de cada distro.
        
        Args:
            limit: Limite de distros para scrape (None = todas)
        
        Returns:
            Lista de distros com todos os dados
        """
        logger.info("ğŸš€ Iniciando scraping completo do DistroWatch...")
        
        # Scrape lista
        distros = self.scrape_distro_list()
        
        if not distros:
            logger.warning("âš ï¸ Nenhuma distro encontrada na lista")
            return []
        
        # Aplica limite se especificado
        if limit:
            distros = distros[:limit]
            logger.info(f"ğŸ“Š Limitando scraping a {limit} distribuiÃ§Ãµes")
        
        logger.info(f"âœ… Scraping completo: {len(distros)} distribuiÃ§Ãµes processadas")
        
        return distros


def test_scraper():
    """Testa o scraper localmente."""
    import json
    
    print("ğŸ§ª Testando CloudScraper...")
    
    scraper = DistroWatchCloudScraper()
    results = scraper.scrape_all(limit=5)
    
    print(f"\nâœ… Resultados: {len(results)} distros")
    print(json.dumps(results, indent=2))


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    test_scraper()
